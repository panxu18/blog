MQ消息的可靠性需要从生产者、消费者、存储三个方面考虑，对于不同MQ产品思路都是类似的，下面分析RocketMQ和Kafka如何保证消息可靠性。

### RocketMQ

- 生产者：producer通过请求确认机制来保证消息发送到broker，producer没有收到broker的确认消息，就会重发消息，直到消息发送成功，这样就能保证在发送阶段消息不会丢失。
- 存储：broker收到producer的消息之后通常会保存在内存中，然后就对producer发出确认，内存中的消息会定时落盘。这里broker宕机这里就会出现消息丢失，如果要保证消息的可靠性设置broker的刷盘方式为同步刷盘。另外，broker使用主从部署时，因为消息还需要写入从服务器，所以可能会出现主从数据不一致，当master宕机不可恢复时就会导致消息丢失。设置主从同步的方式可以提高消息的可靠性。
- 消费者：消费者从broker中拉消息消费时，消费成功会broker发送确认，如果broker没有收到消费者的消息，那么消费者之后会再次收到同一条消息。

### Kafka

- 生产者： 生产者发送消息给broker后，根据broker的返回信息来判断消息发送是否成功，如果失败的话就重试。
  1. 使用send方法之后，接着调用get方法获取调用结果，但是这样会让send变成同步操作。
  2. 通过带回调函数的send方法，并在回调中确认消息是否发送成功。，要将producer的retries重试次数设置大一些，可以保证出现网络问题时可以重试，避免消息丢失。
  3. 设置acks=all，all表示所有副本接收消息后才表示消息发送成功。
  4. replication.factory=3表示每个分区有3个副本，min.insync.replicas表示消息至少需要被写入几个副本。保证replication.factory>min.insync.replicas。
- 存储： kafka引入了多副本机制，一个leader多个follower。消息会被先发送到leader副本，然后follower副本才能从leader副本中拉去消息进行同步。由于leader和follower的数据不一致，在leader宕机无法恢复时就会造成数据丢失。
  1. 设置unclean.leader.election.enable = false，保证不会使用落后原先leader太多的follower作为新leader。

- 消费者：在分区中有一个offset的概念，表示消费者消费到的位置，默认配置下，当消费者拉取消息之后，消费者会自动提交offset。因此，要保证消息可靠消费，需要关闭自动提交offset，等消费完成之后手动提交。